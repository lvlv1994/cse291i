{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from dataloader import Loader\n",
    "import importlib\n",
    "#from subpixel import subpix_conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_activation = tf.nn.leaky_relu\n",
    "def redefine_loss(logits, depths):\n",
    "    logits_flat = tf.reshape(logits, [-1, 304*228])\n",
    "    depths_flat = tf.reshape(depths, [-1, 304*228])\n",
    "    predict=logits_flat\n",
    "    target=depths_flat\n",
    "    d = tf.subtract(predict, target)\n",
    "    square_d = tf.square(d)\n",
    "    sum_square_d = tf.reduce_sum(square_d, 1)\n",
    "    sum_d = tf.reduce_sum(d, 1)\n",
    "    sqare_sum_d = tf.square(sum_d)\n",
    "    cost = tf.reduce_mean(sum_square_d / (55.0*74.0) - 0.5*sqare_sum_d / (55*74)**2)\n",
    "    return cost \n",
    "def accuracy(logits, depths, delta=1.25):\n",
    "    return tf.reduce_mean(tf.cast(tf.maximum(tf.divide(logits, depths), tf.divide(depths, logits))<delta, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(image):\n",
    "    # Hidden layer with 96 neurons\n",
    "    layer_1 = tf.layers.conv2d(image,filters=96,kernel_size=[11,11],strides=4,padding='VALID',activation=default_activation,name='CoarseConv1')\n",
    "    layer_1 = tf.layers.max_pooling2d(layer_1,pool_size=2,strides=2,name='CoarseMax1')\n",
    "    #layer_1 = tf.layers.batch_normalization(layer_1, training=is_training, name='CoarseConvBN1')\n",
    "    \n",
    "    # Hidden layer with 256 neurons\n",
    "    layer_2 = tf.layers.conv2d(layer_1,filters=256,kernel_size=[5,5],strides=1,padding='SAME',activation=default_activation,name='CoarseConv2')\n",
    "    layer_2 = tf.layers.max_pooling2d(layer_2,pool_size=[2,2],strides=2,name='CoarseMax2')\n",
    "    #layer_2 = tf.layers.batch_normalization(layer_2, training=is_training, name='CoarseConvBN2')\n",
    "    \n",
    "    layer_3 = tf.layers.conv2d(layer_2,filters=384,kernel_size=[3,3],strides=1,padding='SAME',activation=default_activation,name='CoarseConv3')\n",
    "    #layer_3 = tf.layers.batch_normalization(layer_3, training=is_training, name='CoarseConvBN3')\n",
    "    \n",
    "    layer_4 = tf.layers.conv2d(layer_3,filters=384,kernel_size=[3,3],strides=1,padding='SAME',activation=default_activation,name='CoarseConv4')\n",
    "    #layer_4 = tf.layers.batch_normalization(layer_4, training=is_training, name='CoarseConvBN4')\n",
    "    layer_5 = tf.layers.conv2d(layer_4,filters=256,kernel_size=[3,3],strides=2,padding='VALID',activation=default_activation,name='CoarseConv5')\n",
    "    #layer_5 = tf.layers.batch_normalization(layer_5, training=is_training, name='CoarseConvBN5')\n",
    "    return layer_5\n",
    "\n",
    "def fully_connect_layer(conv_data,dropout,is_training):\n",
    "    conv_data = tf.reshape(conv_data,[-1,conv_data.shape[1]*conv_data.shape[2]*conv_data.shape[3]])\n",
    "    \n",
    "    layer_1 = tf.layers.dense(conv_data,units=4096,activation=default_activation,name='CoarseFC1')\n",
    "    #layer_1 = tf.layers.batch_normalization(layer_1, training=is_training, name='CoarseFCBN1')\n",
    "    layer_1 = tf.layers.dropout(layer_1,rate=dropout,training=is_training,name='CoarseFCDrop1')\n",
    "    \n",
    "    layer_2 = tf.layers.dense(layer_1,units=4070,activation=None,name='CoarseFC2')\n",
    "    #layer_2 = tf.layers.batch_normalization(layer_2, training=is_training, name='CoarseFCBN2')\n",
    "    out_layer = tf.reshape(layer_2,[-1,55,74,1])\n",
    "    return out_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coarse(image, dropout, is_training):\n",
    "    conv_data = conv_layer(image) #6x8x256\n",
    "    coarse = fully_connect_layer(conv_data,dropout,is_training)\n",
    "#     coarse = subpix_conv2d(conv_data, 128, (5,5), 3)\n",
    "#     coarse = subpix_conv2d(coarse, 64, (5,5), 3)\n",
    "#     coarse = tf.layers.conv2d_transpose(coarse, 1, (2,3), 1)\n",
    "    return coarse #74x55x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine(image, coarse, fine_gate, dropout, is_training):\n",
    "    coarse = tf.cond(fine_gate, lambda : tf.stop_gradient(coarse), lambda : coarse)\n",
    "    layer_1 = tf.layers.conv2d(image,filters=63,kernel_size=[9,9],strides=2,padding='VALID',activation=default_activation,name='FineConv1')\n",
    "    print(layer_1.shape)\n",
    "    #layer_1 = tf.layers.max_pooling2d(layer_1,pool_size=[2,2],strides=2,data_format='channels_last',name='FineMax1')\n",
    "    #layer_1 = tf.layers.batch_normalization(layer_1, training=is_training, name='FineBN1')\n",
    "    layer_2 = tf.layers.conv2d(layer_1,filters=63,kernel_size=[1,1],strides=2,padding='SAME',activation=default_activation,name='FineConv2')\n",
    "    print(layer_2.shape)\n",
    "    print(coarse.shape)\n",
    "    catted = tf.concat([layer_2,coarse],axis=3, name='Fine1to2')\n",
    "    print(catted.shape)\n",
    "    \n",
    "    #tf.image.resize_images(catted, size=(7,7), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    '''\n",
    "    layer_3 = tf.layers.conv2d(catted,filters=64,kernel_size=[5,5],strides=1,padding='SAME',activation=default_activation,name='FineConv3')\n",
    "    print(layer_3.shape)\n",
    "    #layer_3 = tf.layers.batch_normalization(layer_3, training=is_training, name='FineBN2')\n",
    "    layer_4 = tf.layers.conv2d(layer_3,filters=1,kernel_size=[5,5],strides=1,padding='SAME',activation=default_activation,name='FineConv4')\n",
    "    print(layer_4.shape)\n",
    "    #layer_4 = tf.layers.batch_normalization(layer_4, training=is_training, name='FineBN3')\n",
    "    '''\n",
    "\n",
    "    layer_3 = tf.layers.conv2d_transpose(catted,filters=64, kernel_size=[5,5],strides=(2,2),padding='same')\n",
    "    print(layer_3.shape)\n",
    "    layer_4 = tf.layers.conv2d_transpose(layer_3,filters=1, kernel_size=[10,10],strides=(2,2),padding='VALID')\n",
    "    print(layer_4.shape)\n",
    "    ##############get the extra layer from coarse that directly connect to output\n",
    "    extra_coarse_1 = tf.layers.conv2d_transpose(coarse,filters=1, kernel_size=[5,5],strides=(2,2),padding='same')\n",
    "    print(extra_coarse_1.shape)\n",
    "    extra_coarse_2 = tf.layers.conv2d_transpose(extra_coarse_1,filters=1, kernel_size=[10,10],strides=(2,2),padding='VALID')\n",
    "    print(extra_coarse_2.shape)\n",
    "    \n",
    "    out = tf.cond(is_training,\n",
    "                  lambda : tf.cond(fine_gate, lambda : layer_4, lambda : 0.1*layer_4+0.9*extra_coarse_2),#coarse\n",
    "                  lambda : layer_4)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(images,depths,crop_size,scale_range,rot_range,flip):\n",
    "    catted = tf.concat([images, depths], axis=3)\n",
    "    s = tf.random_uniform([], *scale_range)\n",
    "    scaled = tf.image.resize_images(catted, tf.cast(tf.cast(tf.shape(catted)[1:3], tf.float32)*s, tf.int32))\n",
    "    scaled = tf.concat([scaled[...,:-1], tf.divide(scaled[...,-1:], s)], axis=3)\n",
    "    #rotated = tf.contrib.image.rotate(scaled, tf.random_uniform([tf.shape(scaled)[0],], *rot_range)/180*3.14159265)\n",
    "    rotated = scaled\n",
    "    cropped = tf.map_fn(lambda img: tf.random_crop(img, (crop_size[0], crop_size[1], catted.shape[3])), rotated)\n",
    "    if flip:\n",
    "        out = tf.map_fn(lambda img: tf.image.random_flip_left_right(img), cropped)\n",
    "    else:\n",
    "        out = cropped\n",
    "    return out[...,0:3], out[...,3:]\n",
    "\n",
    "def preprocess(images, depths, crop_size, depth_size=(55,74), scale_range=(0.5,1.5), rot_range=(-5,5), flip=True):\n",
    "    image,depth = augment(images, depths, crop_size, scale_range, rot_range, flip)\n",
    "    depth = tf.image.resize_images(depth, depth_size)\n",
    "    return image*2/255-1, depth*2/255-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 110, 148, 63)\n",
      "(?, 55, 74, 63)\n",
      "(?, 55, 74, 1)\n",
      "(?, 55, 74, 64)\n",
      "(?, 110, 148, 64)\n",
      "(?, 228, 304, 1)\n",
      "(?, 110, 148, 1)\n",
      "(?, 228, 304, 1)\n",
      "(?, 228, 304, 1) (?, 228, 304, 1)\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 0.0001\n",
    "DECAY_SPEED = 1/20\n",
    "\n",
    "tf.reset_default_graph() \n",
    "\n",
    "global_step = tf.Variable(0.0, trainable=False)\n",
    "\n",
    "with tf.name_scope('Reader'):\n",
    "    reader = Loader(imagepath='./nyu_datasets/*.jpg', depthpath='./nyu_datasets/*.png', batch_size=4, seed=0)\n",
    "    train_img_reader, train_depth_reader = reader.get_train_reader()\n",
    "    test_img_reader, test_depth_reader = reader.get_test_reader()\n",
    "with tf.name_scope('Preprocess'):\n",
    "    train_imgs, train_depths = preprocess(train_img_reader, train_depth_reader, crop_size=[228,304], depth_size=[228,304])#[55,74])\n",
    "    test_imgs, test_depths = preprocess(test_img_reader, test_depth_reader, crop_size=[228,304], depth_size=[228,304], scale_range=(0.475,0.475), rot_range=(0,0), flip=False)\n",
    "with tf.name_scope('Parameters'):\n",
    "    fine_gate = tf.placeholder_with_default(True,shape=[])\n",
    "    learning_rate = INIT_LR/(1+DECAY_SPEED*global_step)\n",
    "    is_training = tf.placeholder_with_default(False, [])\n",
    "with tf.name_scope('Model'):\n",
    "    img_input = tf.placeholder(tf.float32,[None,228,304,3])\n",
    "    depth_input = tf.placeholder(tf.float32,[None,228,304,1])\n",
    "    coarse_output = coarse(img_input, 0.3, is_training)\n",
    "    refined_output = fine(img_input, coarse_output, fine_gate, 0.3, is_training)\n",
    "with tf.name_scope('Loss'):\n",
    "    loss_op = redefine_loss(refined_output, depth_input)\n",
    "with tf.name_scope('Adam'):\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimizer.minimize(loss_op)\n",
    "print(refined_output.shape,depth_input.shape)\n",
    "with tf.name_scope('Accuracy'):\n",
    "    accuracy_op = accuracy(refined_output, depth_input, 1.25)\n",
    "\n",
    "running_loss_sum = tf.placeholder(tf.float32, [])\n",
    "running_accuracy_sum = tf.placeholder(tf.float32, [])\n",
    "input_image_sum = tf.placeholder(tf.float32, [1,228,304,3])\n",
    "input_depth_sum = tf.placeholder(tf.float32, [1,228,304,1])\n",
    "coarse_sum = tf.placeholder(tf.float32, [1,55,74,1])\n",
    "refined_sum = tf.placeholder(tf.float32, [1,228,304,1])\n",
    "\n",
    "train_summary = tf.summary.merge([\n",
    "    tf.summary.scalar('train_running_loss', running_loss_sum),\n",
    "    tf.summary.scalar('train_running_accuracy', running_accuracy_sum),\n",
    "    tf.summary.scalar('learning_rate', learning_rate),\n",
    "    tf.summary.image('train_input', input_image_sum),\n",
    "    tf.summary.image('train_target', input_depth_sum),\n",
    "    tf.summary.image('train_coarse', coarse_sum),\n",
    "    tf.summary.image('train_output', refined_sum)\n",
    "])\n",
    "test_summary = tf.summary.merge([\n",
    "    tf.summary.scalar('test_loss', running_loss_sum),\n",
    "    tf.summary.scalar('test_accuracy', running_accuracy_sum),\n",
    "    tf.summary.image('test_input', input_image_sum),\n",
    "    tf.summary.image('test_target', input_depth_sum),\n",
    "    tf.summary.image('test_coarse', coarse_sum),\n",
    "    tf.summary.image('test_output', refined_sum)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0 3.0 4.0 5.0 6.0 7.0 "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "Nth_RUN = 'NOBN_linear_augment_0001'\n",
    "training_epochs=1000\n",
    "logs_path = './logs/{}'.format(Nth_RUN)\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    tf.global_variables_initializer().run(session=sess)\n",
    "    tf.local_variables_initializer().run(session=sess)\n",
    "    latest_ckpt = tf.train.latest_checkpoint(logs_path)\n",
    "    if latest_ckpt:\n",
    "        saver.restore(sess, latest_ckpt)\n",
    "        print('Checkpoint recovered', latest_ckpt)\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    # start queue loader (for data)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord = coord)\n",
    "    # Training cycle\n",
    "    training_coarse = 2\n",
    "    while sess.run(tf.assign_add(global_step, 1)) < training_epochs:\n",
    "        print(sess.run(global_step), end=' ')\n",
    "        train_loss = 0\n",
    "        train_accu = 0\n",
    "        for s in range(reader.n_batches()[0]):\n",
    "            batch_img, batch_depth = sess.run([train_imgs, train_depths])\n",
    "            _, cur_loss, cur_accu = sess.run([train_op, loss_op, accuracy_op], feed_dict={img_input:batch_img, \n",
    "                                                           depth_input:batch_depth, \n",
    "                                                           fine_gate:not training_coarse, \n",
    "                                                           is_training:True})\n",
    "            #print(cur_loss)\n",
    "            #print(cur_accu)\n",
    "            training_coarse = training_coarse-1\n",
    "            if training_coarse<0:\n",
    "                training_coarse = 2\n",
    "            #print(reader.size())\n",
    "            train_loss += cur_loss/reader.size()[0]*batch_img.shape[0]/reader.n_batches()[0]\n",
    "            train_accu += cur_accu/reader.size()[0]*batch_img.shape[0]/reader.n_batches()[0]\n",
    "            #print(train_loss)\n",
    "            \n",
    "        I,D = sess.run([train_imgs, train_depths])\n",
    "        C,O = sess.run([coarse_output, refined_output], feed_dict={img_input:I, depth_input:D, is_training:False})\n",
    "        \n",
    "        summary_writer.add_summary(\n",
    "            sess.run(train_summary, \n",
    "                     feed_dict={\n",
    "                         running_loss_sum:train_loss,\n",
    "                         running_accuracy_sum:train_accu,\n",
    "                         input_image_sum:I[-1:,...], \n",
    "                         input_depth_sum:D[-1:,...], \n",
    "                         coarse_sum:C[-1:,...], \n",
    "                         refined_sum:O[-1:,...]}), global_step=sess.run(global_step))\n",
    "        \n",
    "        \n",
    "        test_loss = 0\n",
    "        test_accu = 0\n",
    "        for s in range(reader.n_batches()[1]):\n",
    "            tbatch_img, tbatch_depth = sess.run([test_imgs, test_depths])\n",
    "            cur_loss, cur_accu = sess.run([loss_op, accuracy_op], \n",
    "                                  feed_dict={\n",
    "                                      img_input:tbatch_img,\n",
    "                                      depth_input:tbatch_depth,\n",
    "                                      is_training:False})\n",
    "            test_loss += cur_loss/reader.size()[1]*tbatch_img.shape[0]/reader.n_batches()[1]\n",
    "            test_accu += cur_accu/reader.size()[1]*tbatch_img.shape[0]/reader.n_batches()[1]\n",
    "        TI, TD = sess.run([test_imgs, test_depths])\n",
    "        TC, TO = sess.run([coarse_output, refined_output], feed_dict={img_input:TI,depth_input:TD, is_training:False})\n",
    "        #print(test_loss.shape)\n",
    "        #print(cur_accu.shape)\n",
    "        summary_writer.add_summary(\n",
    "            sess.run(test_summary, \n",
    "                     feed_dict={\n",
    "                         running_loss_sum:test_loss, \n",
    "                         running_accuracy_sum:cur_accu,\n",
    "                         input_image_sum:TI[-1:,...], \n",
    "                         input_depth_sum:TD[-1:,...], \n",
    "                         coarse_sum:TC[-1:,...], \n",
    "                         refined_sum:TO[-1:,...]}), global_step=sess.run(global_step))\n",
    "        \n",
    "        if sess.run(global_step)%10==0:\n",
    "            save_path = saver.save(sess, logs_path+\"/CSE291FinalModel.ckpt\", global_step=global_step)  #save model for second part\n",
    "    # end queue loader\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'nyu_depth_v2_labeled.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "class Loader:\n",
    "    def __init__(self, file='./nyu_depth_v2_labeled.mat', train_ratio=0.9, batch_size=8, allow_smaller_final_batch=False):\n",
    "        self.__datafile = h5py.File(file)\n",
    "        self.__indices = np.arange(self.__datafile['images'].shape[0])\n",
    "        np.random.shuffle(self.__indices)\n",
    "        cut_idx = int(train_ratio*self.__indices.shape[0])\n",
    "        self.__train_indices = self.__indices[:cut_idx]\n",
    "        self.__test_indices = self.__indices[cut_idx:]\n",
    "        self.__bs = batch_size\n",
    "        self.__train_pool = np.array(self.__train_indices)\n",
    "        self.__test_pool = np.array(self.__test_indices)\n",
    "        self.__smaller_final = allow_smaller_final_batch\n",
    "    \n",
    "    @staticmethod\n",
    "    def __get_batch(indices, batch_size):\n",
    "        return np.random.choice(indices, size=batch_size, replace=False)\n",
    "    @staticmethod\n",
    "    def __read_batch(batch, f):\n",
    "        return f['images'][np.sort(batch),...].transpose((0,3,2,1)), f['depths'][np.sort(batch),...].transpose((0,2,1))\n",
    "    \n",
    "    def train_batch(self):\n",
    "        bs = self.__bs\n",
    "        if self.__train_pool.shape[0]<self.__bs:\n",
    "            if self.__smaller_final:\n",
    "                bs = self.__train_pool.shape[0]\n",
    "            else:\n",
    "                self.__train_pool = np.array(self.__train_indices)\n",
    "        batch = self.__get_batch(self.__train_pool, bs)\n",
    "        self.__train_pool = np.setdiff1d(self.__train_pool, batch, assume_unique=True)\n",
    "        if self.__train_pool.shape[0]==0:\n",
    "            self.__train_pool = np.array(self.__train_indices)\n",
    "        return self.__read_batch(batch, self.__datafile)\n",
    "    \n",
    "    def test_batch(self):\n",
    "        bs = self.__bs\n",
    "        if self.__test_pool.shape[0]<self.__bs:\n",
    "            if self.__smaller_final:\n",
    "                bs = self.__test_pool.shape[0]\n",
    "            else:\n",
    "                self.__test_pool = np.array(self.__test_indices)\n",
    "        batch = self.__get_batch(self.__test_pool, bs)\n",
    "        self.__test_pool = np.setdiff1d(self.__test_pool, batch, assume_unique=True)\n",
    "        if self.__test_pool.shape[0]==0:\n",
    "            self.__test_pool = np.array(self.__test_indices)\n",
    "        return self.__read_batch(batch, self.__datafile)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.__train_indices), len(self.__test_indices)\n",
    "    \n",
    "    def n_batches(self):\n",
    "        if self.__smaller_final:\n",
    "            op = np.ceil\n",
    "        else:\n",
    "            op = np.floor\n",
    "        return int(op(len(self.__train_indices)/self.__bs)), int(op(len(self.__test_indices)/self.__bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Dataloader(batch_size=8, allow_smaller_final_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163, 18)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.n_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1304, 145)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "X = keras.layers.Input(shape=(304,228,3), name='Input')\n",
    "Coarse1 = keras.layers.LeakyReLU()(\n",
    "            keras.layers.MaxPool2D(pool_size=2)(\n",
    "                keras.layers.Conv2D(filters=96, \n",
    "                                    kernel_size=11, \n",
    "                                    strides=4)(X)))\n",
    "Coarse2 = keras.layers.LeakyReLU()(\n",
    "            keras.layers.MaxPool2D(pool_size=2)(\n",
    "                keras.layers.Conv2D(filters=256,\n",
    "                                    kernel_size=5,\n",
    "                                    padding='same')(Coarse1)))\n",
    "Coarse3 = keras.layers.LeakyReLU()(\n",
    "            keras.layers.Conv2D(filters=384,\n",
    "                              kernel_size=3,\n",
    "                              padding='same')(Coarse2))\n",
    "Coarse4 = keras.layers.LeakyReLU()(\n",
    "            keras.layers.Conv2D(filters=384,\n",
    "                              kernel_size=3,\n",
    "                              padding='same')(Coarse3))\n",
    "Coarse5 = keras.layers.LeakyReLU()(\n",
    "            keras.layers.MaxPool2D(pool_size=2)(\n",
    "                keras.layers.Conv2D(filters=256,\n",
    "                                  kernel_size=3,\n",
    "                                  padding='same')(Coarse4)))\n",
    "Coarse6 = keras.layers.Dropout(0.1)(\n",
    "            keras.layers.LeakyReLU()(\n",
    "                keras.layers.Dense(units=4096)(Coarse5)))\n",
    "#Coarse7 = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(9), Dimension(6), Dimension(4096)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Coarse6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, (640,480))\n",
    "Coarse1 = tf.layers.max_pooling2d(\n",
    "    inputs = tf.layers.conv2d(\n",
    "                inputs=X, \n",
    "                filters=96, \n",
    "                kernel_size=11, \n",
    "                strides=4, \n",
    "                padding='same'),\n",
    "    pool_size=2,\n",
    "    name='Coarse1')\n",
    "Coarse2 = tf.layers.max_pooling2d(\n",
    "    inputs = tf.layers.conv2d(\n",
    "                inputs=Coarse1,\n",
    "                filters=256,\n",
    "                kernel_size=5,\n",
    "                padding='same'),\n",
    "    pool_size=2,\n",
    "    name='Coarse2')\n",
    "Coarse3 = tf.layers.conv2d(\n",
    "            inputs = Coarse2,\n",
    "            filters=384,\n",
    "            kernel_size=3,\n",
    "            padding='same',\n",
    "            name='Coarse3')\n",
    "Coarse4 = tf.layers.conv2d(\n",
    "            inputs = Coarse3,\n",
    "            filters=384,\n",
    "            kernel_size=3,\n",
    "            padding='same',\n",
    "            name='Coarse4')\n",
    "Coarse5 = tf.layers.max_pooling2d(\n",
    "    inputs = tf.layers.conv2d(\n",
    "                inputs = Coarse4,\n",
    "                filters=256,\n",
    "                kernel_size=3,\n",
    "                padding='same',),\n",
    "    pool_size=2,\n",
    "    name='Coarse5')\n",
    "Coarse6 = tf.layers.dense()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
